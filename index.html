<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-weight: 800;
      color: green;
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/rrclogo.png">
  <title>Satyajit Tourani</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Satyajit Tourani</name>
              </p>
              <!--
              <p>I am a staff research scientist at <a href="https://ai.google/research">Google Research</a>, where I work on computer vision and computational photography. At Google I've worked on <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>.
              </p>
          	-->
		    <p>
			   At present I am working at TCS-Research as  Predoctoral research under Dr. Brojeshwar Bhowmick. I am working on the Social Robot Navigation.			   
			   At IIIT Hyderabad, I did my master's degree in research. Under Prof. Madhava Krishna's supervision at the Robotics Research Center. During my master's programme, I focused mostly on the topic of visual place recognition in both indoor and outdoor settings. I've published my work at prestigious robotics and vision conferences like IROS, ICRA and VISAPP.
			   <p>
			   Prior to joining IIIT Hyderabad, I worked at Amazon as an SDE intern. I was a member of the INGC (Indian Giftcard) team. I was in charge of building a system which involved the end consumer to receive an SMS message anytime he performed a giftcard-related action (Buy, Redeem, Expiry etc).</p>
			    <p>
			   My other interests lie in competitive programming and playing fps games.</p>
			  <!--  Additionally, I am also interested in exploring the interplay of neuroscience, computer vision and machine learning to understand how we humans perceive, interact, plan, and navigate in a multitude of scenarios so that we can impart embodied agents with more advanced perception capabilities.
			    
			    Particularly, I am intersted in the <strong>visual SLAM</strong>, <strong>trajectory prediction</strong>, <strong>multi-object tracking</strong>, <strong>3D reconstruction</strong>; especially in a monocular setting.  I am also interest in the interplay of neuroscience, machine learning and computer vision to understand how we humans perceive, interact, plan, and navigate in a multitude of scenarios so that we can impart embodied agents with more advanced perception capabilities. For example, in our recent work (submitted in ICRA2021) we explored human visual attention for a more social, cooperative, and non-distracting robot navigation amidst dynamic human agents.

			    
			    
          	</p>
		<!--    
          	<p>	
			I am particularly interested in applying <em>classical/geometric</em> techniques 
			(such as bundle adjustment and pose-graph optimization) in conjunction with <em>deep learning</em> 
			(for tasks like semantic keypoint inference and single view depth prediction) to solve interesting/challenging
			machine vision problems such as dense visual SLAM in highly dynamic environment, motion forecasting of humans/objects, etc..
          	-->	
          		<!-- 
          			I am specifically interested in applying classical techniques (such as bundle adjustment and pose-graph optimization) in conjunction with deep learning (for tasks like semantic keypoint inference and single view depth prediction) to rather bring the dynamism of the scene in the (monocular visual) SLAM systems, and not ignore it. 
          		-->
              </p>
              <p>      <!--        	
		      My <a href="data/MS_Thesis_defense_condensed.pdf">masters thesis</a> focuses on <strong>reconstruction of moving (or static) vehicles on arbitrary road plane
		      profiles from a moving monocular camera</strong>. I leverage feature prediction capabilities of deep networks tightly coupled with 
		      classical geometric methods such as multi-view stereo and bundle adjustment to jointly optimize the pose-shape of the 
		      vehicle and the local road plane geometry. <a href="data/MS_Thesis_defense_condensed.pdf">[LINK TO PRESENTATION].</a>-->
              </p>


              <p align=center>                
                <a href="mailto:tourani.satyajit@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/touranisatyajit">GitHub</a> &nbsp/&nbsp
                <a href="data/satyajit-cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=943lKscAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://in.linkedin.com/in/satyajittourani/"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/crop-cropped.png">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>             

            </td>
          </tr>
        </table>
	      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

		<tr>

              
                <papertitle>Exploring Social Motion Latent Space and Human Awareness</papertitle>              
              <br>              
              Junaid Ahmed Ansari, Satyajit Tourani, Gourav Kumar and Brojeshwar Bhowmick          
              <br>
              <em>IROS</em>, 2023 &nbsp <font color="red"></font>(*equal contribution)
              <br>
		    <a href=""> Paper(Coming Soon)</a>
		<p></p>
              <p>This work proposes a novel approach to social
robot navigation by learning to generate robot controls from
a social motion latent space. By leveraging this social motion
latent space, the proposed method achieves significant improve-
ments in social navigation metrics such as success rate, naviga-
tion time, and trajectory length while producing smoother (less
jerk and angular deviations) and more anticipatory trajecto-
ries. The superiority of the proposed method is demonstrated
through comparison with baseline models in various scenarios.
Additionally, the concept of humans’ awareness towards the
robot is introduced into the social robot navigation framework,
showing that incorporating human awareness leads to shorter
and smoother trajectories owing to humans’ ability to positively
interact with the robot.</p>
            </td>
          </tr>
	
		
         <tr>

              
                <papertitle>RoRD: Rotation-Robust Descriptors and Orthographic Views for Local Feature Matching</papertitle>              
              <br>              
              Udit Singh Parihar*, Aniket Gujarathi*, Kinal Mehta*, <strong>Satyajit Tourani*</strong>, Sourav Garg, Michael Milford, K Madhava Krishna          
              <br>
              <em>IROS</em>, 2021 &nbsp <font color="red"></font>(*equal contribution)
              <br>
		    <a href="https://arxiv.org/pdf/2103.08573"> Paper</a>
		<p></p>
              <p>In this paper, we present a novel framework that combines the learning of invariant descriptors through data augmentation and orthographic viewpoint projection. We propose rotation-robust local descriptors, learnt through training data augmentation based on rotation homographies, and a correspondence ensemble technique that combines vanilla feature correspondences with those obtained through rotation-robust features.</p>
            </td>
          </tr>
          
	 <tr>

              
                <papertitle>Early bird: Loop closures from opposing viewpoints for perceptually-aliased indoor environments</papertitle>
		    
              <br>              
              <strong>Satyajit Tourani*</strong>, Dhagash Desai*, Udit Singh Parihar*, Sourav Garg, Ravi Kiran Sarvadevabhatla, Michael Milford, K Madhava Krishna<br>
              <em>VISAPP</em>, 2021 &nbsp <font color="red"></font> (*equal contribution)
              <br>
              <a href="https://arxiv.org/pdf/2010.01421">Paper </a>
			  <p></p>
              <p>Significant recent advances have been made in Visual Place Recognition (VPR), feature correspondence and
localization due to deep-learning-based methods. However, existing approaches tend to address, partially or
fully, only one of two key challenges: viewpoint change and perceptual aliasing. In this paper, we present
novel research that simultaneously addresses both challenges by combining deep-learnt features with geometric transformations based on domain knowledge about navigation on a ground-plane, without specialized hardware (e.g. downwards facing cameras, etc.).
              <br>
            </td>
          </tr>
		
          <tr>
           
              
                <papertitle>Topological mapping for Manhattan-like repetitive environments</papertitle>
              
              <br>              
              Sai Shubodh Puligilla*, <strong>Satyajit Tourani*</strong>, Tushar Vaidya*, Udit Singh Parihar*, Ravi Kiran Sarvadevabhatla, K Madhava Krishna          
              <br>
              <em>ICRA</em>, 2020 &nbsp <font color="red"></font> (*equal contribution)
              <br>
              <a href="https://arxiv.org/pdf/2002.06575.pdf?ref=https://githubhelp.com">Paper</a>              
			  <p></p>
              <p>In this work We showcase a topological mapping framework
for a challenging indoor warehouse setting. At the most abstract
level, the warehouse is represented as a Topological Graph
where the nodes of the graph represent a particular warehouse
topological construct (e.g. rackspace, corridor) and the edges
denote the existence of a path between two neighbouring
nodes or topologies. At the intermediate level, the map is
represented as a Manhattan Graph where the nodes and edges
are characterized by Manhattan properties and as a Pose Graph
at the lower-most level of detail. The topological constructs
are learned via a Deep Convolutional Network while the
relational properties between topological instances are learnt
via a Siamese-style Neural Network. In the paper, we show
that maintaining abstractions such as Topological Graph and
Manhattan Graph help in recovering an accurate Pose Graph
starting from a highly erroneous and unoptimized Pose Graph.
We show how this is achieved by embedding topological and
Manhattan relations as well as Manhattan Graph aided loop
closure relations as constraints in the backend Pose Graph
optimization framework. The recovery of near ground-truth
Pose Graph on real-world indoor warehouse scenes vindicate
the efficacy of the proposed framework.</p>
            </td>
          </tr>
      
          

        </table>

             	


	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              Thanks to Dr. Jon Baron for the web page <a href="https://github.com/jonbarron/website">template</a>.
            </td>
          </tr>
        </table>
        </td>

    </tr>    
  </table>
</body>

</html>
